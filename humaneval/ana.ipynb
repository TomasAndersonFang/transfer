{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genrating patches for 162 bugs among 162 bugs\n"
     ]
    }
   ],
   "source": [
    "result_file = './rcl_humaneval_patches_results_pbf_ff.json'\n",
    "meta_file = '../../model_outputs/humaneval/rcl_humaneval_patches_megadiff_pbf_ff.json'\n",
    "with open(result_file, 'r') as f:\n",
    "    data = [json.loads(line) for line in f]\n",
    "with open(meta_file) as f:\n",
    "    meta = [json.loads(line) for line in f.readlines()]\n",
    "print(\"Genrating patches for {} bugs among {} bugs\".format(len(data), len(meta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genrating patches for 162 bugs among 162 bugs\n"
     ]
    }
   ],
   "source": [
    "# For chatgpt results\n",
    "result_file = './gpt35_humaneval_sf_patches_results.json'\n",
    "meta_file = '/home/senf/workshop/input-output-repr/megadiff/samples_HumanEvalJava_function-to-function_.jsonl'\n",
    "with open(result_file, 'r') as f:\n",
    "    data = [json.loads(line) for line in f]\n",
    "with open(meta_file) as f:\n",
    "    meta = [json.loads(line) for line in f.readlines()]\n",
    "print(\"Genrating patches for {} bugs among {} bugs\".format(len(data), len(meta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating plausible patches for 107 bugs\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "match_cnt = 0\n",
    "for sample in data:\n",
    "    if \"Plausible\" in sample[\"test_results\"] or \"Match\" in sample[\"test_results\"]:\n",
    "        cnt += 1\n",
    "    if \"Match\" in sample[\"test_results\"]:\n",
    "        match_cnt += 1\n",
    "print(\"Generating plausible patches for {} bugs\".format(cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_dict = {}\n",
    "for each in data:\n",
    "\n",
    "    index_dict[each['bug_id']] = each['test_results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'identifier': 'FIB',\n",
       " 'buggy_code': '    public static int fib(int n) {\\n        return fib(n - 1) + fib(n - 2);\\n    }\\n',\n",
       " 'fixed_code': '    public static int fib(int n) {\\n        if (n == 0 || n == 1)\\n            return n;\\n        return fib(n - 1) + fib(n - 2);\\n    }\\n',\n",
       " 'prompt_strategy': 'function-to-function',\n",
       " 'prompt': '    public static int fib(int n) {\\n        return fib(n - 1) + fib(n - 2);\\n    }\\n',\n",
       " 'ground_truth': '--- src/main/java/humaneval/buggy/FIB.java\\t2023-11-15 10:23:58.315244237 +0000\\n+++ src/main/java/humaneval/buggy/FIB.java\\t2023-11-15 10:23:51.159232578 +0000\\n@@ -10,8 +10,6 @@\\n \\n public class FIB {\\n     public static int fib(int n) {\\n-        if (n == 0 || n == 1)\\n-            return n;\\n         return fib(n - 1) + fib(n - 2);\\n     }\\n }\\n'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, each in enumerate(meta):\n",
    "    if each['identifier'] in index_dict:\n",
    "        meta[idx]['test_results'] = index_dict[each['identifier']]\n",
    "    else:\n",
    "        meta[idx]['test_results'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_match(candidate, gold):\n",
    "    pred_lines = candidate.splitlines(True)\n",
    "    gold_lines = gold.splitlines(True)\n",
    "    # remove empty lines\n",
    "    # pred_lines = [line for line in pred_lines if line.strip() != \"\"]\n",
    "    # gold_lines = [line for line in gold_lines if line.strip() != \"\"]\n",
    "    if len(pred_lines) != len(gold_lines):\n",
    "        return False\n",
    "    for pred_line, gold_line in zip(pred_lines, gold_lines):\n",
    "        # remove beginning and trailing whitespaces\n",
    "        pred_line = ''.join(pred_line.split())\n",
    "        gold_line = ''.join(gold_line.split())\n",
    "        if pred_line != gold_line:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating line-matched patches for 52 bugs\n"
     ]
    }
   ],
   "source": [
    "# For fl patches of RepairLlaMA\n",
    "\n",
    "for idx, each in enumerate(meta):\n",
    "    if each['test_results'] != []:\n",
    "        output = each['output']\n",
    "        test_results = each['test_results']\n",
    "        gold_patch = each['gold_patch']\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    patch_list = []\n",
    "\n",
    "    for value in each['output'].values():\n",
    "        patch_list.append(value['output_patch'])\n",
    "    \n",
    "    for i in range(len(test_results)):\n",
    "        \n",
    "        if test_results[i] == \"Plausible\":\n",
    "            match_flag = is_match(patch_list[i], gold_patch)\n",
    "            if match_flag:\n",
    "                meta[idx]['test_results'][i] = \"Match\"\n",
    "\n",
    "cnt = 0\n",
    "for each in meta:\n",
    "    if 'Match' in each['test_results']:\n",
    "        cnt += 1\n",
    "print(\"Generating line-matched patches for {} bugs\".format(cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating line-matched patches for 50 bugs\n"
     ]
    }
   ],
   "source": [
    "# For fl patches of Chatgpt\n",
    "index_dict = {}\n",
    "for each in data:\n",
    "    index_dict[each['bug_id']] = each['patches']\n",
    "\n",
    "for idx, each in enumerate(meta):\n",
    "    if each['identifier'] in index_dict:\n",
    "        meta[idx]['output'] = index_dict[each['identifier']]\n",
    "    else:\n",
    "        meta[idx]['output'] = []\n",
    "\n",
    "for idx, each in enumerate(meta):\n",
    "    if each['test_results'] != []:\n",
    "        output = each['output']\n",
    "        test_results = each['test_results']\n",
    "        gold_patch = each['fixed_code']\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    # patch_list = []\n",
    "\n",
    "    # for value in each['output'].values():\n",
    "    #     patch_list.append(value['output_patch'])\n",
    "    \n",
    "    for i in range(len(test_results)):\n",
    "        \n",
    "        if test_results[i] == \"Plausible\":\n",
    "            match_flag = is_match(output[i], gold_patch)\n",
    "            if match_flag:\n",
    "                meta[idx]['test_results'][i] = \"Match\"\n",
    "\n",
    "cnt = 0\n",
    "for each in meta:\n",
    "    if 'Match' in each['test_results']:\n",
    "        cnt += 1\n",
    "print(\"Generating line-matched patches for {} bugs\".format(cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'patches'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/senf/workshop/input-output-repr/eval_result/humaneval/ana.ipynb Cell 10\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B130.237.222.185/home/senf/workshop/input-output-repr/eval_result/humaneval/ana.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     test_results \u001b[39m=\u001b[39m each[\u001b[39m'\u001b[39m\u001b[39mtest_results\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B130.237.222.185/home/senf/workshop/input-output-repr/eval_result/humaneval/ana.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     gold_patch \u001b[39m=\u001b[39m each[\u001b[39m'\u001b[39m\u001b[39mgold_patch\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B130.237.222.185/home/senf/workshop/input-output-repr/eval_result/humaneval/ana.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     patch_list \u001b[39m=\u001b[39m each[\u001b[39m'\u001b[39;49m\u001b[39mpatches\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B130.237.222.185/home/senf/workshop/input-output-repr/eval_result/humaneval/ana.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(patch_list) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(test_results):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B130.237.222.185/home/senf/workshop/input-output-repr/eval_result/humaneval/ana.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39mprint\u001b[39m(each[\u001b[39m'\u001b[39m\u001b[39mbug_id\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[0;31mKeyError\u001b[0m: 'patches'"
     ]
    }
   ],
   "source": [
    "# For diff patches\n",
    "for idx, each in enumerate(meta):\n",
    "    if each['test_results'] != []:\n",
    "        test_results = each['test_results']\n",
    "        gold_patch = each['gold_patch']\n",
    "        patch_list = each['patches']\n",
    "        \n",
    "    if len(patch_list) != len(test_results):\n",
    "        print(each['bug_id'])\n",
    "        print(len(patch_list), len(test_results))\n",
    "        break\n",
    "    \n",
    "    for i in range(len(test_results)):\n",
    "        \n",
    "        if test_results[i] == \"Plausible\":\n",
    "            match_flag = is_match(patch_list[i], gold_patch)\n",
    "            if match_flag:\n",
    "                meta[idx]['test_results'][i] = \"Match\"\n",
    "\n",
    "cnt = 0\n",
    "for each in meta:\n",
    "    if 'Match' in each['test_results']:\n",
    "        cnt += 1\n",
    "print(\"Generating line-matched patches for {} bugs\".format(cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./gpt35_humaneval_sf_patches_results_line_match.json', 'w') as f:\n",
    "    for each in meta:\n",
    "        f.write(json.dumps(each) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating line-matched patches for 52 bugs\n"
     ]
    }
   ],
   "source": [
    "result_index = {}\n",
    "for each in meta:\n",
    "    result_index[each['bug_id']] = each['test_results'] if each['test_results'] != [] else []\n",
    "# Update data list\n",
    "for idx, each in enumerate(data):\n",
    "    if \"Plausible\" in each[\"test_results\"]:\n",
    "        data[idx][\"test_results\"] = result_index[each[\"bug_id\"]]\n",
    "cnt = 0\n",
    "for each in data:\n",
    "    if 'Match' in each['test_results']:\n",
    "        cnt += 1\n",
    "print(\"Generating line-matched patches for {} bugs\".format(cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update data to json file\n",
    "with open(result_file, 'w') as f:\n",
    "    for each in data:\n",
    "        f.write(json.dumps(each) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read ast results\n",
    "with open('./ast-match-result/rcl_humaneval_patches_results_pbf_ff_ast_match.json', 'r') as f:\n",
    "    data = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bug id</th>\n",
       "      <th>Compile fail</th>\n",
       "      <th>Test fail</th>\n",
       "      <th>Plausible</th>\n",
       "      <th>Match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ADD</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ADD_ELEMENTS</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>ADD_EVEN_AT_ODD</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ALL_PREFIXES</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>ANTI_SHUFFLE</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ANY_INT</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>BELOW_THRESHOLD</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>BELOW_ZERO</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>BF</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>BY_LENGTH</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             bug id  Compile fail  Test fail  Plausible  Match\n",
       "39              ADD             0          9          0      1\n",
       "13     ADD_ELEMENTS             0         10          0      0\n",
       "74  ADD_EVEN_AT_ODD             7          3          0      0\n",
       "8      ALL_PREFIXES             2          7          0      1\n",
       "90     ANTI_SHUFFLE             7          3          0      0\n",
       "14          ANY_INT             0          9          1      0\n",
       "30  BELOW_THRESHOLD             1          8          0      1\n",
       "54       BELOW_ZERO             8          2          0      0\n",
       "21               BF             1          9          0      0\n",
       "78        BY_LENGTH             1          5          1      3"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "for sample in data:\n",
    "    result_dict = {\"bug id\": sample[\"bug_id\"]}\n",
    "    test_results = sample[\"test_results\"]\n",
    "    # test_results = sample[\"results\"]\n",
    "    for test_result in test_results:\n",
    "        if test_result == \"Plausible\":\n",
    "            result_dict[test_result] = result_dict.get(test_result, 0) + 1\n",
    "        elif test_result == \"Match\":\n",
    "            result_dict[test_result] = result_dict.get(test_result, 0) + 1\n",
    "        elif test_result == \"Complie fail\":\n",
    "            result_dict[test_result] = result_dict.get(test_result, 0) + 1\n",
    "        elif test_result == \"Test fail\":\n",
    "            result_dict[test_result] = result_dict.get(test_result, 0) + 1\n",
    "        else:\n",
    "            result_dict[test_result] = result_dict.get(test_result, 0) + 1\n",
    "    results.append(result_dict)\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "# change NaN to 0\n",
    "df = df.fillna(0)\n",
    "\n",
    "# Change 1-4 cloumes float to int\n",
    "df['Compile fail'] = df['Compile fail'].astype(int)\n",
    "df['Plausible'] = df['Plausible'].astype(int)\n",
    "df['Test fail'] = df['Test fail'].astype(int)\n",
    "df['Match'] = df['Match'].astype(int)\n",
    "\n",
    "df = df[['bug id', 'Compile fail', 'Test fail', 'Plausible', 'Match']]\n",
    "\n",
    "# sort by bug id\n",
    "df = df.sort_values(by=['bug id'])\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n",
      "54\n",
      "346\n",
      "1042\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "# count the number of bugs that Plausible > 0 or Match > 0\n",
    "print(len(df[(df['Plausible'] > 0) | (df['Match'] > 0)]))\n",
    "# count the number of bugs that Match > 0\n",
    "print(len(df[df['Match'] > 0]))\n",
    "# count the total number of Compile fail\n",
    "print(df['Compile fail'].sum())\n",
    "# count the total number of Test fail\n",
    "print(df['Test fail'].sum())\n",
    "# count the total number of Plausible\n",
    "print(df['Plausible'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "apr_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
